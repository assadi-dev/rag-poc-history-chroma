# Assistant de Chat RAG (Retrieval-Augmented Generation)

Ce projet est la preuve de concept d'un assistant de chat utilisant le concept de **RAG** (Retrieval-Augmented Generation). Il permet de poser des questions sur des documents locaux en utilisant des mod√®les de langage (LLM) via **Ollama**, avec une base de donn√©es vectorielle **ChromaDB** pour la recherche de contexte.

## üöÄ Fonctionnalit√©s

- **Recherche S√©mantique** : Utilise des embeddings pour trouver les passages les plus pertinents dans vos documents.
- **R√©ponses Contextuelles** : L'IA r√©pond en se basant uniquement sur les informations fournies (√©vite les hallucinations).
- **Interface CLI Riche** : Une interface en ligne de commande √©l√©gante gr√¢ce √† `rich` (panneaux, spinners, markdown).
- **Persistance** : Stockage des embeddings dans une base ChromaDB locale.
- **Gestion de l'historique** : Supporte l'historique de conversation via la gestion de session.

## üõ†Ô∏è Pr√©requis

Avant de commencer, assurez-vous d'avoir install√© :
1. [Python 3.10+](https://www.python.org/)
2. [Ollama](https://ollama.com/) (pour faire tourner les mod√®les localement)

## üì¶ Installation

1. **Cloner le d√©p√¥t** :
   ```bash
   git clone <url-du-depot>
   cd rag-poc-history-chroma
   ```

2. **Cr√©er un environnement virtuel** :
   ```bash
   python -m venv venv
   # Sur Windows
   .\venv\Scripts\activate
   # Sur macOS/Linux
   source venv/bin/activate
   ```

3. **Installer les d√©pendances** :
   ```bash
   pip install -r requirements.txt
   ```

4. **Installer le mod√®le Ollama** :
   Ce projet utilise par d√©faut `llama3.2`. T√©l√©chargez-le avec :
   ```bash
   ollama pull llama3.2
   ```

## ‚öôÔ∏è Configuration

Cr√©ez un fichier `.env` √† la racine du projet (optionnel si vous utilisez les valeurs par d√©faut) :
```env
# Exemple de configuration
OLLAMA_BASE_URL=http://localhost:11434
```

## üéÆ Utilisation

Pour lancer l'assistant de chat :

```bash
python main.py
```

### Commandes disponibles dans le chat :
- `/help` : Affiche l'aide
- `/quit` ou `/exit` : Quitte l'application
- `/clear` : Efface l'historique de la conversation actuelle

## üìÇ Structure du projet

- `main.py` : Point d'entr√©e de l'application.
- `src/cli/` : Logique de l'interface utilisateur.
- `src/vectorstore/` : Gestion de la base de donn√©es vectorielle ChromaDB.
- `src/embedding/` : Service de g√©n√©ration d'embeddings via Ollama.
- `src/text_splitter/` : D√©coupage des documents en segments.
- `src/documents_loader/` : Chargement des documents (inclut des mocks pour la d√©mo).

## üìù Licence

Libre d'utilisation pour vos propres projets de recherche IA.
